{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0243f580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/raymondeds/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from nltk.tokenize import word_tokenize\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "# special matplotlib argument for improved plots\n",
    "from matplotlib import rcParams\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b3e4907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_int</th>\n",
       "      <th>confidence_int</th>\n",
       "      <th>review</th>\n",
       "      <th>forum</th>\n",
       "      <th>abstract</th>\n",
       "      <th>conf_year</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>review_num_tokens</th>\n",
       "      <th>replyto</th>\n",
       "      <th>title</th>\n",
       "      <th>decision</th>\n",
       "      <th>comment</th>\n",
       "      <th>conf_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>there is a lot of recent work on link-predicti...</td>\n",
       "      <td>tGZu6DlbreV</td>\n",
       "      <td>this paper studies learning logic rules for re...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[there, is, a, lot, of, recent, work, on, link...</td>\n",
       "      <td>1537</td>\n",
       "      <td>tGZu6DlbreV</td>\n",
       "      <td>Final Decision</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>There is a consensus among the reviewers that ...</td>\n",
       "      <td>ICLR2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>in this paper, the author proposes rnnlogic fo...</td>\n",
       "      <td>tGZu6DlbreV</td>\n",
       "      <td>this paper studies learning logic rules for re...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[in, this, paper, ,, the, author, proposes, rn...</td>\n",
       "      <td>722</td>\n",
       "      <td>tGZu6DlbreV</td>\n",
       "      <td>Final Decision</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>There is a consensus among the reviewers that ...</td>\n",
       "      <td>ICLR2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>this paper focuses on learning logic rules via...</td>\n",
       "      <td>tGZu6DlbreV</td>\n",
       "      <td>this paper studies learning logic rules for re...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[this, paper, focuses, on, learning, logic, ru...</td>\n",
       "      <td>236</td>\n",
       "      <td>tGZu6DlbreV</td>\n",
       "      <td>Final Decision</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>There is a consensus among the reviewers that ...</td>\n",
       "      <td>ICLR2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>in this work, the authors illustrate an approa...</td>\n",
       "      <td>tGZu6DlbreV</td>\n",
       "      <td>this paper studies learning logic rules for re...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[in, this, work, ,, the, authors, illustrate, ...</td>\n",
       "      <td>121</td>\n",
       "      <td>tGZu6DlbreV</td>\n",
       "      <td>Final Decision</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>There is a consensus among the reviewers that ...</td>\n",
       "      <td>ICLR2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>pros:\\n\\n- the different attention techniques ...</td>\n",
       "      <td>uKhGRvM8QNH</td>\n",
       "      <td>knowledge distillation, in which a student mod...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[pros, :, -, the, different, attention, techni...</td>\n",
       "      <td>338</td>\n",
       "      <td>uKhGRvM8QNH</td>\n",
       "      <td>Final Decision</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>After the rebuttal stage, all reviewers lean p...</td>\n",
       "      <td>ICLR2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25163</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>the author proposes the use of low-rank matrix...</td>\n",
       "      <td>rkaRFYcgl</td>\n",
       "      <td>deep learning consists in training neural netw...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[the, author, proposes, the, use, of, low-rank...</td>\n",
       "      <td>383</td>\n",
       "      <td>rkaRFYcgl</td>\n",
       "      <td>ICLR committee final decision</td>\n",
       "      <td>Reject</td>\n",
       "      <td>The reviewers seem to agree that the framework...</td>\n",
       "      <td>ICLR2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25164</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the paper proposes a low-rank version of pass-...</td>\n",
       "      <td>rkaRFYcgl</td>\n",
       "      <td>deep learning consists in training neural netw...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[the, paper, proposes, a, low-rank, version, o...</td>\n",
       "      <td>82</td>\n",
       "      <td>rkaRFYcgl</td>\n",
       "      <td>ICLR committee final decision</td>\n",
       "      <td>Reject</td>\n",
       "      <td>The reviewers seem to agree that the framework...</td>\n",
       "      <td>ICLR2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25165</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>the authors study the use of low-rank approxim...</td>\n",
       "      <td>rkaRFYcgl</td>\n",
       "      <td>deep learning consists in training neural netw...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[the, authors, study, the, use, of, low-rank, ...</td>\n",
       "      <td>209</td>\n",
       "      <td>rkaRFYcgl</td>\n",
       "      <td>ICLR committee final decision</td>\n",
       "      <td>Reject</td>\n",
       "      <td>The reviewers seem to agree that the framework...</td>\n",
       "      <td>ICLR2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25166</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>​there have been numerous works ​on learning f...</td>\n",
       "      <td>BkUDvt5gg</td>\n",
       "      <td>this paper presents a simple end-to-end model ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[​there, have, been, numerous, works, ​on, lea...</td>\n",
       "      <td>326</td>\n",
       "      <td>BkUDvt5gg</td>\n",
       "      <td>ICLR committee final decision</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Without revisions to this paper or a rebuttal ...</td>\n",
       "      <td>ICLR2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25167</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>this submission proposes a letter-level decode...</td>\n",
       "      <td>BkUDvt5gg</td>\n",
       "      <td>this paper presents a simple end-to-end model ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[this, submission, proposes, a, letter-level, ...</td>\n",
       "      <td>531</td>\n",
       "      <td>BkUDvt5gg</td>\n",
       "      <td>ICLR committee final decision</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Without revisions to this paper or a rebuttal ...</td>\n",
       "      <td>ICLR2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25168 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating_int  confidence_int  \\\n",
       "0               6             4.0   \n",
       "1               7             4.0   \n",
       "2               6             2.0   \n",
       "3               8             1.0   \n",
       "4               6             4.0   \n",
       "...           ...             ...   \n",
       "25163           4             4.0   \n",
       "25164           5             NaN   \n",
       "25165           6             4.0   \n",
       "25166           6             4.0   \n",
       "25167           7             5.0   \n",
       "\n",
       "                                                  review        forum  \\\n",
       "0      there is a lot of recent work on link-predicti...  tGZu6DlbreV   \n",
       "1      in this paper, the author proposes rnnlogic fo...  tGZu6DlbreV   \n",
       "2      this paper focuses on learning logic rules via...  tGZu6DlbreV   \n",
       "3      in this work, the authors illustrate an approa...  tGZu6DlbreV   \n",
       "4      pros:\\n\\n- the different attention techniques ...  uKhGRvM8QNH   \n",
       "...                                                  ...          ...   \n",
       "25163  the author proposes the use of low-rank matrix...    rkaRFYcgl   \n",
       "25164  the paper proposes a low-rank version of pass-...    rkaRFYcgl   \n",
       "25165  the authors study the use of low-rank approxim...    rkaRFYcgl   \n",
       "25166  ​there have been numerous works ​on learning f...    BkUDvt5gg   \n",
       "25167  this submission proposes a letter-level decode...    BkUDvt5gg   \n",
       "\n",
       "                                                abstract  conf_year  \\\n",
       "0      this paper studies learning logic rules for re...       2021   \n",
       "1      this paper studies learning logic rules for re...       2021   \n",
       "2      this paper studies learning logic rules for re...       2021   \n",
       "3      this paper studies learning logic rules for re...       2021   \n",
       "4      knowledge distillation, in which a student mod...       2021   \n",
       "...                                                  ...        ...   \n",
       "25163  deep learning consists in training neural netw...       2017   \n",
       "25164  deep learning consists in training neural netw...       2017   \n",
       "25165  deep learning consists in training neural netw...       2017   \n",
       "25166  this paper presents a simple end-to-end model ...       2017   \n",
       "25167  this paper presents a simple end-to-end model ...       2017   \n",
       "\n",
       "                                           review_tokens  review_num_tokens  \\\n",
       "0      [there, is, a, lot, of, recent, work, on, link...               1537   \n",
       "1      [in, this, paper, ,, the, author, proposes, rn...                722   \n",
       "2      [this, paper, focuses, on, learning, logic, ru...                236   \n",
       "3      [in, this, work, ,, the, authors, illustrate, ...                121   \n",
       "4      [pros, :, -, the, different, attention, techni...                338   \n",
       "...                                                  ...                ...   \n",
       "25163  [the, author, proposes, the, use, of, low-rank...                383   \n",
       "25164  [the, paper, proposes, a, low-rank, version, o...                 82   \n",
       "25165  [the, authors, study, the, use, of, low-rank, ...                209   \n",
       "25166  [​there, have, been, numerous, works, ​on, lea...                326   \n",
       "25167  [this, submission, proposes, a, letter-level, ...                531   \n",
       "\n",
       "           replyto                          title         decision  \\\n",
       "0      tGZu6DlbreV                 Final Decision  Accept (Poster)   \n",
       "1      tGZu6DlbreV                 Final Decision  Accept (Poster)   \n",
       "2      tGZu6DlbreV                 Final Decision  Accept (Poster)   \n",
       "3      tGZu6DlbreV                 Final Decision  Accept (Poster)   \n",
       "4      uKhGRvM8QNH                 Final Decision  Accept (Poster)   \n",
       "...            ...                            ...              ...   \n",
       "25163    rkaRFYcgl  ICLR committee final decision           Reject   \n",
       "25164    rkaRFYcgl  ICLR committee final decision           Reject   \n",
       "25165    rkaRFYcgl  ICLR committee final decision           Reject   \n",
       "25166    BkUDvt5gg  ICLR committee final decision           Reject   \n",
       "25167    BkUDvt5gg  ICLR committee final decision           Reject   \n",
       "\n",
       "                                                 comment conf_name  \n",
       "0      There is a consensus among the reviewers that ...  ICLR2021  \n",
       "1      There is a consensus among the reviewers that ...  ICLR2021  \n",
       "2      There is a consensus among the reviewers that ...  ICLR2021  \n",
       "3      There is a consensus among the reviewers that ...  ICLR2021  \n",
       "4      After the rebuttal stage, all reviewers lean p...  ICLR2021  \n",
       "...                                                  ...       ...  \n",
       "25163  The reviewers seem to agree that the framework...  ICLR2017  \n",
       "25164  The reviewers seem to agree that the framework...  ICLR2017  \n",
       "25165  The reviewers seem to agree that the framework...  ICLR2017  \n",
       "25166  Without revisions to this paper or a rebuttal ...  ICLR2017  \n",
       "25167  Without revisions to this paper or a rebuttal ...  ICLR2017  \n",
       "\n",
       "[25168 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_csv('../data/reviews.csv')\n",
    "df_submissions = pd.read_csv('../data/Submissions.csv')\n",
    "df_dec = pd.read_csv('../data/decision.csv')\n",
    "df_keyword = pd.read_csv('../data/submission_keyword.csv')\n",
    "\n",
    "df_rs = pd.merge(df_reviews[['rating_int','confidence_int','review','forum']], df_submissions[['abstract','id','conf_year']], left_on='forum', right_on='id', how = 'inner')\n",
    "df_rs['review'] = df_rs['review'].str.lower()\n",
    "df_rs['abstract'] = df_rs['abstract'].str.lower()\n",
    "df_rs['review_tokens'] = df_rs['review'].apply(word_tokenize)\n",
    "df_rs['review_num_tokens'] = df_rs['review_tokens'].apply(len)\n",
    "\n",
    "df_data = pd.merge(df_rs, df_dec, left_on='forum', right_on='forum', how = 'inner').drop([\n",
    "                                                         'id_x',\n",
    "                                                         'id_y',\n",
    "                                                         'tcdate',\n",
    "                                                         'tmdate',\n",
    "                                                         'number',\n",
    "                                                         'confidence'],axis = 1)\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d00e959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|█████████████████████████████| 929/929 [00:00<00:00, 2.76MB/s]\n",
      "Downloading: 100%|███████████████████████████| 501M/501M [00:11<00:00, 42.0MB/s]\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|███████████████████████████| 899k/899k [00:00<00:00, 3.55MB/s]\n",
      "Downloading: 100%|███████████████████████████| 456k/456k [00:00<00:00, 3.50MB/s]\n",
      "Downloading: 100%|█████████████████████████████| 239/239 [00:00<00:00, 1.01MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive', 'score': 0.9873846769332886}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Import the necessary libraries\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Step 3: Load the pre-trained model and tokenizer\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "# Step 4: Define the text for sentiment analysis\n",
    "text = \"I love using Hugging Face's Transformers library! It's amazing.\"\n",
    "\n",
    "# Step 5: Perform sentiment analysis\n",
    "result = sentiment_analysis(text)\n",
    "\n",
    "# Step 6: Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "573888be",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1721) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1721].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msentiment_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreview\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:140\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/pipelines/base.py:1074\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1074\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/pipelines/base.py:1081\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1080\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1081\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/pipelines/base.py:990\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m    989\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 990\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:167\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1208\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1208\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1219\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1220\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:812\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    811\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 812\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1721) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1721].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "sentiment_analysis(df_data.review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, tokenizer, max_length=512):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    chunks = []\n",
    "    chunk = \"\"\n",
    "    for sentence in sentences:\n",
    "        if len(tokenizer.encode(chunk + sentence, add_special_tokens=False)) <= max_length:\n",
    "            chunk += \" \" + sentence\n",
    "        else:\n",
    "            chunks.append(chunk.strip())\n",
    "            chunk = sentence\n",
    "    if chunk:\n",
    "        chunks.append(chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# Step 8: Perform sentiment analysis on each chunk\n",
    "results = [sentiment_analysis(chunk) for chunk in chunks]\n",
    "\n",
    "# Step 9: Aggregate the results\n",
    "positive_score = sum(res[0]['score'] for res in results if res[0]['label'] == 'POSITIVE')\n",
    "negative_score = sum(res[0]['score'] for res in results if res[0]['label'] == 'NEGATIVE')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
